---
title: "kasper munk rasmussen"
page-layout: full
title-block-banner: true
---

My name is Kasper. My interests include machine learning, LLMs, computational biology and computational neuroscience and AI safety. I did a Master's degree in Computer Science from ETH ZÃ¼rich, focusing mostly on machine learning, and subsequently I have worked as a full-stack software developer at a large Danish software consultancy on a Danish government project.. I am currently looking for a job that stokes my passion. Feel free to contact me.

**[Blog](posts.html)** - Though I have a very disorganized and non-polished blog, you might get some sense of my interests. Feel free to reach out if you'd like to discuss any topic.

## Selected Projects

* [intercebd.com](https://intercebd.com) - With intercebd.com you can collect and annotate and propose LLM responses. You can create SFT and DPO fine-tuning datasets, and use them with OpenAI's fine-tuning service or push the datasets to Huggingface in ChatML format. Built with a FastAPI/Postgres backend and OpenRouter. [GitHub](https://github.com/kmrasmussen/intersebd)

* CS MSc Thesis: Understanding Features in
Superposition in Transformer
Language Models ([PDF](https://kmrasmussen.com/files/pdf/thesis.pdf)): In 2023, concurrently with Anthropic's first SAEs trained on larger LLMs, I formalized notions of superposition that allowed for falsifiable experiments, and showed restricted kinds of superposition in realistic pre-trained Transformer LLMs using linear probes and causal interventions. I was supervised by [Mor Geva](https://mega002.github.io/).
