[
  {
    "objectID": "posts/thoughtadventures1/index.html",
    "href": "posts/thoughtadventures1/index.html",
    "title": "meditation attractors",
    "section": "",
    "text": "when doing breath meditation, mindwandering is an important notion. we can perhaps imagine that the mind follows a trajectory in some kind of space, \\(x(t) \\in \\mathcal{X}\\). We can also imagine that maybe this trajectory is stochastic in some sense, but maybe will wait.\nI will use it as a word “introspectively” for “what i conclude when i try to think about what i experience in meditation”.\nIntrospectively, time is very fine-grained an consists of a single percept. So in that case we have to think of \\(\\mathcal{X}\\) as a set of percpets. These percepts are complex objects, and one important aspect is that they differ by many “ooms” in how much they cause some kind of reaction. This means that some percept, it can be an internal image of a person, can have a certain kind of salience. Introspectively, percepts with a high value are “on average” followed by more of percepts that are “related”.\nSimplistically we might imagine some kind of entity that controls inputs from multiple different sources. These sources may be more “sensory” or they might be more “internal”, such as images generated by fantasies or planning etc.\nI then imagine \\(x(t)\\) as a kind of controlled sampling from these sources, where each source has its own trajectories and you get a sample from one of them.\nThis controlled sampler is a mechanism of attention. I then imagine that we can view the space from two perspectives, we can view it as discrete moments where we get a sample from each, or we can look at the relative abundance of samples from each source, almost as if we are looking across small intervals \\(\\Delta t\\).\nI don’t know whether to think of these sources as specific brain areas or more distributed, for now we are restricting to a kind of combination of introspection and formalizing, where we try to throw around ideas for formalizations of what we introspect. Introspection is different from awareness of the things, it invovles a kind of balance between rationalization and awareness.\nHave you ever seen these videos showing a world map and the change of borders as different countries conquer each other an so on? There is some kind of finite resource, the area of land in the world and then there are these entities, countries, that vary in their territory. New ones can arise at some point and also end at some point."
  },
  {
    "objectID": "posts/thoughtadventures1/index.html#criticality-in-statistical-mechanics",
    "href": "posts/thoughtadventures1/index.html#criticality-in-statistical-mechanics",
    "title": "meditation attractors",
    "section": "criticality in statistical mechanics",
    "text": "criticality in statistical mechanics\nIn statistical mechanics, scale free is related to criticality. Consider a (2d) grid/lattice of points, that can take on values -1 or +1. A specific configuration of -1 or 1 is the state of the system. We are not concerned about how it evolves, but about the distribution. A Boltzman distribution is a distribution that can be written \\(p(x) \\sim \\exp(-\\beta H(x))\\). If we have a function \\(H(x)\\) (a Hamiltonian) that assigns a scalar value (“energy”) to a specific configuration \\(x\\) of the grid, then we can get a distribution over configurations. This distribution depends on how we choose our H function, but once that is fixed it also depends on \\(\\beta\\). In statmech foundations of thermodynamics \\(\\beta\\) is literally associated with the literal temperature of the system \\(\\beta \\propto 1/T\\), but we can consider it more general. The picture is rather that we have some parameters like \\(\\beta\\) and they determine the distribution on the random field (eg the grid), but it is easier if we think of a continuous field rather than a grid. So this is just an explanation of what it could mean that we have a random field, with a specific correlation function, and we can imagine that there are ways in which this random field is translation invariant and rotation invaration so that we only care about distances of points, so we have \\(G(r)\\) for the correlation. As we said, there might be a parameter such as \\(\\beta\\) that influences the distribution and therefore the random field, and therefore it can also influence the correlation function. In particular we can imagine the correlation decays with distance r, but how fast depends on the parameter such as temperature \\(T\\) \\[\nG(r; T) \\sim \\exp(-r/\\xi(T))\n\\] this \\(\\xi(T)\\) is called the correlation length. Statistical mechanics is used to describe phase transitions in systems, where systems changes from behaving in one way to a “qualitatively” different way. We often hear the example of ice and water, the same things but different temperature, but this stuff with criticality is used to describe “second order phase transitions”, and water to ice is not that so not all phase transitions are like that. But such a phase transition happens at some “temperature” or other value of some parameter, and the relation is that it is a this special temperature we call it \\(T_c\\) that the correlation is instead a power law \\[\nG(r;T) \\sim r^{-\\alpha}\n\\] this means that there are “stronger” correlations between distant points, not in the dynamic sense but under the boltzman distribution.\nFor the critical point, as \\(T\\) comes closer to \\(T_c\\) the correlation length becomes longer and longer, and it diverges \\[\n\\lim_{T \\to T_c} \\xi(T) = \\infty\n\\] but also, and i am not sure about the exact relatinship, it is modelled close to T as \\[\n\\xi(T) \\sim |T - T_c|^{-\\nu}\n\\] where \\(\\nu\\) is the correlation length exponent, and you can see how this means that it become larger and larger as we get closer.\nWith the scaling hypothesis the power law decay and exponential decays is bridged somehow with a function \\(f(u) = \\exp(-u)\\) that becomes constant near the critical point \\(T_c\\) so that the correlation function can be written in general as \\[\nG(r; T) \\sim \\frac{1}{r^{d-2+\\eta}}f(\\frac{r}{\\xi(T)})\n\\] so that because f is exponential when not close to \\(T_c\\) that part will dominate and because it is constant close to \\(T_c\\) the fraction is what matters, and the fraction is just where instead of writing \\(r^{-\\alpha}\\) the exponent is now \\(\\alpha = d-2+\\eta\\), where \\(d\\) is some constant and \\(\\eta\\) is the important exponent for power law now.\nIt does not just jump directly from exponential to power law exactly at \\(T_c\\), also if \\(T_c\\) is continouous what does it even mean for a system to be “exactly” \\(T_c\\). So there is something called the scaling hypothesis that describes like as \\(T\\) goes towards \\(T_c\\) in the tiny neighborhood around \\(T\\), then there is way of"
  },
  {
    "objectID": "posts/curiousadventures1/index.html",
    "href": "posts/curiousadventures1/index.html",
    "title": "curious adventures 1",
    "section": "",
    "text": "brain things\nwhat is the first thing i want to know? there is on the order of 100b neurons, people throw around the number 86 billion. okay, but there are not only neurons. how many non-neurons are there? okay, interesting, 4o says also O(100b) glial cells.\nwhat are glial cells? okay it looks like at least in the brain, i need mainly to know 3 types of glial cells:\n\n50% oligodendrocytes - a type of glial cell that wraps around the axon forming myelin, speeding up electric signaling.\n30% astro - maintain extracellular matrix, blood flow\n10% microglia - immune cells, pruning synapses, remove debris\n\nso i guess astrocytes are the most important.\n\nthey clear excess neurotransmitters like glutamate, so there is not too much which would result in overactivation of the brain, so that seems quite important for even computation.\nwhen a brain region becomes active the astrocytes sense changes in neurotransmitters and signal to blood vessels to dilate, crazy. called neurovascular coupling, important for understanding fMRI.\nrelease signals that influence synapses, so strength, learning, plasticity\ncan become “reactive astrocytes” in infection, alzheimers etc.\n\nokay that is enough for me for now about astrocytes. and the oligodendrocytes kind of makes sense to me not going deeper with that.\nthere is 1e8 neurons and 1e8 glial cells. but like oligodendrocytes are forming myelin always or also different things, and in that case is one oligodendrocyte only responsible for one axon, and how many axons? okay oligodendrocytes myelinate multiple axons. 1 axon per neuron but they can branch. estimated that 50% of the axons in the brain are myelinated but depends on regions. okay the primary difference is gray and white matter: 90% of white, and maybe 20% of gray.\nbut i did not learn what white and gray is. okay, it sounds a bit bullshitish, not easy enough to get a clear answer. roughly\n\ngray matter: high number of somas per volume\nwhite matter: low number of somas per volume AND high number of myelinated axons per volume\n\nat least i will run with this. so now i am getting a picture of the brain as having some kind of volume in R^3 and there is some kind of neuron soma count measure that describes how many somas are in a specific region, and then abstracting it as a density even though not continous giving neuron soma density. And then there is an axon count measure and axon count density and myelinated axon count measure. And these are the interesting things, and gray and white matter are simplifications.\n(okay, just got distracted because presented 4o that i wanted to think in terms of measures and it wanted to go off with fiber bundles. so learned that the tangent bundle is the a disjoiint union of the tangent spaces for each point on the manifold, disjoint in the sense that you keep track of which point it came from. so disjoint union is a bit like enumerate in python, you keep an index.)\nokay so where were we. we have neurons with somas and axons and glial cells especially astrocytes and oligodendrocytes. so we are still looking at it from afar. something about energy. how much energy is it using and are neurons using more energy than glial cells?\n\nthe energy usage is on the order of 20 W and roughly 20% of the brain’s energy.\nneurons use 75% and glial cells then less than 20%.\n\nthe reason why they use relatively much has to do with action transmission (ion gradients, glutamate release/reuptake)\nokay so one thing is the density of neurons and the density of glial cells and their relationships. we saw that the notion of gray matter means that neuron soma density is not uniform, is the astrocytes the same way. ok it sounds like i should think of astrocyte density being related to neuron density, because neurons “need” astrocytes, so more neurons need more astrocytes. so astrocyte denisty is not uniform. locally it can be viewed a bit as a regular lattice.\nokay i wonder how one can know these kind of things. spatial transcriptomics of neuronal cell cultures? some methods can do single cells RNA others do aggregate per “spot”? Okay it sounds like you take a mouse brain flash freeze it make a slice for example from the cortex (barbaric unless it already was dying) of 10 \\(\\mu m\\) (mu means micro so one 1 \\(\\mu m\\) is 1e-6m).\n\nThe soma of a neuron is on the order of 10 micrometers, 1e-5 meters.\nsame for astrocytes 10 micrometers, but that is the cell body, it has “processes extending” that are on the order of 100 micrometers which would be its radius.\n\nhmm, i am starting to think about how i should imagine it. if i have a cube with sidelength 100 micrometers, giving what proportion of the volume is taken up by different things? 4o says\n\n10% neuron somas\n10* glial somas\n45% glial and neuron processes (dendrites axons etc)\n20% extracellular space with water and ions and neurotransmitters etc\n5% capillaries\n\nand they form some kind of soft tissue.\nok that was quite a high degree of “exploitation” in this line, a lot of focus on astrocytes etc. i will continue a bit\none of the things we learned was 75% of energy going to neurons because of spiking. i can imagine energy requirements changing over time, after all that is what fmri is about, but are there some regions that are just more energy intesive, and is that mostly predicted by neuron soma density?\nfirst, like how can we measure? FDG is a glucose that is modified to emit positrons and can then image with PET-scan. Cortex, especially frontal and visual cortex, uses a lot of glucose.\n\n\ninside cells\nso we have these cels they are maybe 10 micrometers? what’s going on inside there. there is a nucleus, i guess it is like a ball. it is roughly 5 micrometers diameter, it takes up 10% of the volume. does that match? yeah it is okay. and the mitrochondria also 10% only one nucleus and multiple mitochrondira?\n\norder of 100 to 1000 mitochrondria per cell\nshaped like 0.5x2 micrometers\n\ngreat and inside the nucleus, the chromatin fills up quite well even though not taking up all the volume\n\norder of 10-100 chromosomes, 46 for humans\n3e9 basepairs total, varying from 50 to 250 million base pairs per chromosome, decreasing pretty linearly with rank\n\n\n\n\nChromosome lengths\n\n\n\nokay and it is like this: 8 histone proteins form as 2x2x2 box and order of 100 base pairs wrap around it\non one side is a H1 histone where the dna enters and exits\norder of 10-100 base pairs of linker dna to next structure\nthe structures are called nucleosomes\n\n\n\n\nNucleosome cartoon\n\n\n\nthe word chromatin somehow refers to all of these nucleosomes and some other proteins etc not super clear\nword chromosome also being used a bit weird, focused on when the cell is diving etc, but also numbering them. so each chromosome there is “chromatin” for that chromosome somewhere in the cell, seems you can say “the chromatin for chromosome 11”\nthere are 3 RNA-polymerases, it is number 2 that is doing all the the transcription for real proteins.\ncan transcribe sections that are longer than is on a single nucleosome so there is a crazy dance with other protein complexes like FACT etc that unfold the nucleosome etc.\nmultiple different RNA-polymerase-2’s can be transcribing at the same time at the same interval\nspeed is O(1K) basepairs per minute, can vary by factor 3x depending\nO(50K) RNA-polymerase-2’s inside the nucleus at a single time. O(15K) transcribing at a given time.\nO(1e6) transcripts in the cell at given time, O(1e10) proteins in the cell at given time, one transcript can be translated to protein multiple times\n30% of the volume in cytoplasma taken up by macromoleucles like RNA and protein. 50% is protein, 25% RNA. I am confused concluded that proteins were much more abundant? it’s because RNA is much larger, nucleotides are bigger than amino acids. think 4o might be starting to hallucinate now that i am inquiring about this.\nokay amino acids are O(50) Å^3 (1Å = 0.1 nanometer, 1e-10 meters) and nucleotides O(500) so one order of magnitude difference, but we had 3 ooms difference in abundance of rna and protein.\nokay seems it is because of rRNA in ribosomes very huge, and makes up 80% of RNA in the cell\nthe ribosome is made up with a core part of it being rRNA that is why it is huge.\ntranslation rate is O(10) AA/s, 30-60 seconds per protein typical\nO(1e6) ribosomes in the cell, ~20 nm in diameter, ~7K nucleotides for the rRNA."
  },
  {
    "objectID": "posts/rambling001/index.html",
    "href": "posts/rambling001/index.html",
    "title": "Notes on neural scaling and its value to biology",
    "section": "",
    "text": "I saw a plot recently, showing the size of scRNA-seq datasets according to release date. Tahoe-100M includes 100M cells and at least looking at this plot, it looks like we have had an exponential increase in the size of the of the largest data sets.\n\n\n\nTahoe-100M\n\n\nSimilar growth in dataset sizes have happened in genomics and elsewhere.\nA clear question that arises in this context is then: Can we leverage the growth in data and convert it to value?\nFor LLMs, the story has been that as compute costs have decreased, we (they) have been able to train on larger datasets, but the main point is that pre-training has allowed for actually useful products like chatbots.\nAs pre-training has scaled there might have been diminishing returns, and statements by OpenAI regarding GPT-4.5 being the last in the series of large models can be seen as an indication that there has been a limit to pre-training, which has then been taken over by another regime of scaling RL. In any of these cases of scaling, the core is that we have found a way to make the investment in compute worth it, found a way to actually harness the data. Relevant to this question is neural scaling laws\n\nNeural Scaling laws\n\n\n\nChinchilla\n\n\nModern machine learning has entered a paradigm, where scaling laws play an important role both in practice and at the theoretical level. In the regime where we are not bottlenecked by data (though scaling laws do not need this), it has been observed that there are relationships between data size \\(D\\), number of parameters in model \\(P\\), and floating points operations \\(C\\) (compute), that are quite clean. Scaling laws are not restricted to these quantities, and people are actively investigating other relationships and quantities such as batch size and learning rate. One example of an observed scaling law is in the area of compute optimal training \\[\nL_C = E + c_D D^{-\\alpha_D} + c_P P^{-\\alpha_P}\n\\]\nConsider the case where we are training a generative model \\(q(x)\\) to minimize cross-entropy \\(H(p_{data},q)\\) (maximise likelihood of model under data distribution). The cross-entropy can be divided into entropy of the data distribution and the KL-divergence of data distribution to model \\[\nH(p_{data},q) = H(p_{data}) + KL(p_{data}||q)\n\\] Scaling laws these are based on fitting parametric function to the data we have about training runs of different sizes etc, so there are limits to how seriously we should take a specific formula for scaling laws, but in this picture \\(E\\) corresponds to the inherent entropy of the data distribution, the noise level.\nLooking at the scaling law, in this picture the KL divergence which is always non-negative is being driven to zero as we increase D and N. How fast depends on constants \\(\\alpha_D\\) and \\(\\alpha_P\\). The image is now one where you decide how many FLOPs you are willing to use to train your model, and then determine the optimal number of parameters of your model and how much data you are going to train on.\nAs has been clear for a long time, this of course ignores the fact that reducing the number of flops needed to reach your desired level of loss is a small part of the picture. After training when you want to make use of the models, bigger models are unwieldy, they require more expensive hardware accelerators to run them on, and ofc they require more flops to run, have higher latency (time to first token generated) and throughput (number of tokens generated per second) than smaller models.\nJust as importantly, the loss you reach in pre-training does not directly tell you how well you will perform on a downstream task you care about. After you have pre-trained your model, you want to post-train it, tuning it to do the thing you care about, like being a good chatbot or agent. Only once you have signs that lower loss is robustly correlated with better performance can you justify acquiring the flops and data needed to get a pre-trained model with the low loss that you want.\n\n\nThe value of performance\nIn the context of LLMs, pre-training data is relatively abundant, even if there is a lot of work to do about ensuring quality of data. In the domain of post-training the abundance of data depends on the task, you might be limited in terms of quality preference data (which response from the chatbot is better, answer A or B?), but in some cases such as software and computer-use agents, given sufficient work, there is the possibility of generating abundant synthetic data, that is directly valuable, by letting agents interact with an environment in a way that closely mimicks the final use case.\nIt seems that in biology, the picture becomes a bit more muddy. The performance of an LLM on a suite of benchmark can give at least a partial picture of the overall quality, and especially for benchmarks which aim to closely mimick a final use case, it gets close to being a description of the economic value of using the model.\nComputational biology methods often are diverse, some methods can give you certain information that can then be used in a variety of ways, and at some point downstream of all these methods being applied, and applied the right way, we might simplistically view it as there being derived some scientific understanding of value or changes of health care outcomes of value.\nI am trying to get at some kind of picture where given a certain model with a certain performance on a benchmark, such a model has a certain value for final use cases.\nThere is an observed market, where chatbot providers provide subscriptions and user’s are paying for access to a model with a certain performance. We are not in a situation where model providers can smoothly trade-off inference cost with performance but this is not unimaginable at all. We could use this to make a simplistic picture of the situation. Assume we simplify performance to a scalar value \\(E\\) even though it we cannot in practice, then we can now imagine for a fixed performance \\(E\\) there exist demand and supply curves with equilibrium \\(P_*^E\\) where \\(Q^E_d(P) = Q^E_s(P)\\). We are now having a collection of such markets indexed by performance, and a function \\(P_*(E)\\), being one way of describing the value of performance.\nSuch a thing is hard to imagine for biology."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "kasper munk rasmussen",
    "section": "",
    "text": "My name is Kasper. My interests include machine learning, LLMs, computational biology and computational neuroscience and AI safety. I did a Master’s degree in Computer Science from ETH Zürich, focusing mostly on machine learning, and subsequently I have worked as a full-stack software developer at a large Danish software consultancy on a Danish government project.. I am currently looking for a job that stokes my passion. Feel free to contact me.\nBlog - Though I have a very disorganized and non-polished blog, you might get some sense of my interests. Feel free to reach out if you’d like to discuss any topic."
  },
  {
    "objectID": "index.html#selected-projects",
    "href": "index.html#selected-projects",
    "title": "kasper munk rasmussen",
    "section": "Selected Projects",
    "text": "Selected Projects\n\nintercebd.com - With intercebd.com you can collect and annotate and propose LLM responses. You can create SFT and DPO fine-tuning datasets, and use them with OpenAI’s fine-tuning service or push the datasets to Huggingface in ChatML format. Built with a FastAPI/Postgres backend and OpenRouter. GitHub\nCS MSc Thesis: Understanding Features in Superposition in Transformer Language Models (PDF): In 2023, concurrently with Anthropic’s first SAEs trained on larger LLMs, I formalized notions of superposition that allowed for falsifiable experiments, and showed restricted kinds of superposition in realistic pre-trained Transformer LLMs using linear probes and causal interventions. I was supervised by Mor Geva."
  },
  {
    "objectID": "index.html#videos",
    "href": "index.html#videos",
    "title": "kasper munk rasmussen",
    "section": "Videos",
    "text": "Videos\nI am exploring streaming my screen, talking about machine learning and programming.\n\n\n\n\n\n\n\n\n\n\nBasic Math of Supervised Deep Learning with Cross-Entropy\n\n\n\nml\n\n\n\n\nJun 16, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "kasper munk rasmussen",
    "section": "Recent posts",
    "text": "Recent posts\nSee all posts →\n\n\n\n\n\n\n\n\n\n\nmacromacroscale\n\n\n\n\n\n\n\n\nJun 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nmeditation attractors\n\n\n\n\n\n\n\n\nJun 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\ncurious adventures 1\n\n\n\n\n\n\n\n\nJun 3, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "kasper munk rasmussen",
    "section": "Education",
    "text": "Education\n\nMaster of Computer Science, ETH Zürich\n09/2021 - 11/2023\n\nMajor in Machine Intelligence, minor in Theoretical Computer Science\nElectives focused on neuroscience and bioinformatics\nThesis (top grade): Understanding Features in Superposition in Transformer Language Models\nGPA: 5.4/6\n\n\n\nBachelor of Computer Science, University of Copenhagen\n09/2018 - 06/2021\n\nData Science specialization\nThesis (top grade): Unsupervised learning of objects and concepts with a focus on medical images\nGPA: 11.6/12"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "posts",
    "section": "",
    "text": "macromacroscale\n\n\n\n\n\n\n\n\nJun 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nmeditation attractors\n\n\n\nmeditation\n\n\n\n\n\n\n\n\n\nJun 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\ncurious adventures 1\n\n\n\n\n\n\n\n\nJun 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\njax adventures 001\n\n\n\n\n\n\n\n\nJun 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on neural scaling and its value to biology\n\n\n\nstream-of-thought\n\n\n\n\n\n\n\n\n\nJun 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHow does static FC compare across sessions in MyConnectome Project?\n\n\n\nneuroscience\n\nfmri\n\n\n\n\n\n\n\n\n\nJun 2, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/jaxadventure1/index.html",
    "href": "posts/jaxadventure1/index.html",
    "title": "jax adventures 001",
    "section": "",
    "text": "I have been wanting to learn more Jax, so I will go on an a Jax adventure.\n\nimport jax\nimport jax.numpy as jnp\nimport flax.linen as nn\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nThese imports should be sufficient for what I’d need.\nI saw there is some kind of selfattention module in flax. Apparently Flax Linen is being taken over by Flax NNX\n\nfrom flax import nnx\nmy_selfattention = nnx.MultiHeadAttention(\n  num_heads=2,\n  in_features=10,\n  qkv_features=6,\n  out_features=12,\n  decode=False,\n  rngs=nnx.Rngs(0)\n)\n\nOkay now I have this object, I assume it is a nnx module. Usually then it has to be initialized with parameters separately, but why is there then an rngs associated with it?\n\nprint(my_selfattention)\n\n\nMultiHeadAttention( # Param: 282 (1.1 KB)\n\n  num_heads=2,\n\n  in_features=10,\n\n  qkv_features=6,\n\n  out_features=12,\n\n  dtype=None,\n\n  param_dtype=float32,\n\n  broadcast_dropout=True,\n\n  dropout_rate=0.0,\n\n  deterministic=None,\n\n  precision=None,\n\n  kernel_init=&lt;function variance_scaling.&lt;locals&gt;.init at 0x73e5c28e2700&gt;,\n\n  out_kernel_init=None,\n\n  bias_init=&lt;function zeros at 0x73e5c362c5e0&gt;,\n\n  out_bias_init=None,\n\n  use_bias=True,\n\n  attention_fn=&lt;function dot_product_attention at 0x73e5c28e2200&gt;,\n\n  decode=False,\n\n  normalize_qk=False,\n\n  qkv_dot_general=None,\n\n  out_dot_general=None,\n\n  qkv_dot_general_cls=None,\n\n  out_dot_general_cls=None,\n\n  head_dim=3,\n\n  query=LinearGeneral( # Param: 66 (264 B)\n\n    in_features=(10,),\n\n    out_features=(2, 3),\n\n    axis=(-1,),\n\n    batch_axis=FrozenDict({}),\n\n    use_bias=True,\n\n    dtype=None,\n\n    param_dtype=float32,\n\n    kernel_init=&lt;function variance_scaling.&lt;locals&gt;.init at 0x73e5c28e2700&gt;,\n\n    bias_init=&lt;function zeros at 0x73e5c362c5e0&gt;,\n\n    precision=None,\n\n    dot_general=None,\n\n    dot_general_cls=None,\n\n    promote_dtype=&lt;function promote_dtype at 0x73e5c28e2160&gt;,\n\n    kernel=Param( # 60 (240 B)\n\n      value=Array(shape=(10, 2, 3), dtype=dtype('float32'))\n\n    ),\n\n    bias=Param( # 6 (24 B)\n\n      value=Array(shape=(2, 3), dtype=dtype('float32'))\n\n    )\n\n  ),\n\n  key=LinearGeneral( # Param: 66 (264 B)\n\n    in_features=(10,),\n\n    out_features=(2, 3),\n\n    axis=(-1,),\n\n    batch_axis=FrozenDict({}),\n\n    use_bias=True,\n\n    dtype=None,\n\n    param_dtype=float32,\n\n    kernel_init=&lt;function variance_scaling.&lt;locals&gt;.init at 0x73e5c28e2700&gt;,\n\n    bias_init=&lt;function zeros at 0x73e5c362c5e0&gt;,\n\n    precision=None,\n\n    dot_general=None,\n\n    dot_general_cls=None,\n\n    promote_dtype=&lt;function promote_dtype at 0x73e5c28e2160&gt;,\n\n    kernel=Param( # 60 (240 B)\n\n      value=Array(shape=(10, 2, 3), dtype=dtype('float32'))\n\n    ),\n\n    bias=Param( # 6 (24 B)\n\n      value=Array(shape=(2, 3), dtype=dtype('float32'))\n\n    )\n\n  ),\n\n  value=LinearGeneral( # Param: 66 (264 B)\n\n    in_features=(10,),\n\n    out_features=(2, 3),\n\n    axis=(-1,),\n\n    batch_axis=FrozenDict({}),\n\n    use_bias=True,\n\n    dtype=None,\n\n    param_dtype=float32,\n\n    kernel_init=&lt;function variance_scaling.&lt;locals&gt;.init at 0x73e5c28e2700&gt;,\n\n    bias_init=&lt;function zeros at 0x73e5c362c5e0&gt;,\n\n    precision=None,\n\n    dot_general=None,\n\n    dot_general_cls=None,\n\n    promote_dtype=&lt;function promote_dtype at 0x73e5c28e2160&gt;,\n\n    kernel=Param( # 60 (240 B)\n\n      value=Array(shape=(10, 2, 3), dtype=dtype('float32'))\n\n    ),\n\n    bias=Param( # 6 (24 B)\n\n      value=Array(shape=(2, 3), dtype=dtype('float32'))\n\n    )\n\n  ),\n\n  query_ln=None,\n\n  key_ln=None,\n\n  out=LinearGeneral( # Param: 84 (336 B)\n\n    in_features=(2, 3),\n\n    out_features=(12,),\n\n    axis=(-2, -1),\n\n    batch_axis=FrozenDict({}),\n\n    use_bias=True,\n\n    dtype=None,\n\n    param_dtype=float32,\n\n    kernel_init=&lt;function variance_scaling.&lt;locals&gt;.init at 0x73e5c28e2700&gt;,\n\n    bias_init=&lt;function zeros at 0x73e5c362c5e0&gt;,\n\n    precision=None,\n\n    dot_general=None,\n\n    dot_general_cls=None,\n\n    promote_dtype=&lt;function promote_dtype at 0x73e5c28e2160&gt;,\n\n    kernel=Param( # 72 (288 B)\n\n      value=Array(shape=(2, 3, 12), dtype=dtype('float32'))\n\n    ),\n\n    bias=Param( # 12 (48 B)\n\n      value=Array(shape=(12,), dtype=dtype('float32'))\n\n    )\n\n  ),\n\n  rngs=None,\n\n  cached_key=None,\n\n  cached_value=None,\n\n  cache_index=None\n\n)"
  },
  {
    "objectID": "posts/srfcmyconnectome/index.html",
    "href": "posts/srfcmyconnectome/index.html",
    "title": "How does static FC compare across sessions in MyConnectome Project?",
    "section": "",
    "text": "One could imagine that one day it might be possible that a psychiatric patient could be undergoing some brain imaging sessions, and some computational model of the subject’s brain will be used for guiding treatment.\nMyConnectome Project has a lot of brain imaging recording from the same person. Perhaps it could be used as a playground to ask some questions about what possibilities and limitations there may be for this idea of making a personalized brain model for a patient.\n\nFormal notations for fMRI\nA common object in computational analyses of fMRI is the functional connectivity matrix. Very simplified, fMRI gives you at each timepoint a 3d matrix \\(\\omega_t \\in \\mathbb{R}^{W \\times H \\times D}\\), describing “activity” at each coordinate. Therefore this \\(v_t\\) is a quite high-dimensional object and is reduced by aggregating activity in different “brain areas”.\nWe can think of \\(\\Omega = [W] \\times [H] \\times [D]\\) as the domain on which the original signal lives, where \\([W] = \\{0,...,W-1\\}\\).\nNow each \\(v_t\\), is a mapping \\(v_t : \\Omega \\to \\mathbb{R}\\), from each point in the domain to a value of activity.\nThis domain \\(\\Omega\\) obviously has some kind of structure, in some cases associate voxels with their Euclidean coordinates. This makes some sense, since we are considering \\(\\Omega\\) as the space of immediate signals. We might be trying to infer something about what the structure of the underlying brain state leading to a volume or a time series of volumes has been, but this brain state would then live in another space than the space of recorded volumes.\nAn “atlas” or “parcellation” is a partition of \\(\\Omega\\), a set of disjoint subsets. In some cases we might not require that the union of the sets constite \\(\\Omega\\), because what if some coordinate is outside the brain? We get a volume that is a box but the brain is not a box. We write \\(A_1, ..., A_N \\subset \\Omega\\) of disjoint subsets \\(A_n\\) of the domain. N will often be in the order of 100.\nNow we can consider looking at a specific area, and consider only the parts of the signal in that area. \\(v_t^m : A_n \\to \\mathbb{R}\\). We can also consider the some method of aggregation: If an area \\(A_n\\) has cardinality \\(|A_n|\\), then we can consider a the set \\(\\{v_t^n(\\omega) \\in \\mathbb{R} | \\forall \\omega \\in A_n \\} \\subseteq \\mathbb{R}\\), the set of all activities in that brain region at that time. One way of aggregating is to just take the mean, call it \\(\\mu^n_t \\in \\mathbb{R}\\).\nGiven some selection of an “atlas”, we say that we parcellate a recording \\(\\{v_t\\}_{t\\in[T]}\\) by converting it to parcellated time series \\(\\{\\mu_t^n\\}_{t\\in [T],n\\in[N]}\\).\nThe parcellated time series constitute a reduced representation of the recording, in practice it will be a matrix \\(M \\in \\mathbb{R}^{T\\times N}\\).\nOne hopes that this object \\(M\\) captures something meaningful about the brain recording, by averaging over the smaller activities, that the noise is thereby reduced.\nOne processing step that might be applied is to filter the frequencies. Since the our recording \\(v_t\\) is made at discrete timesteps \\(t\\), that are made every TR (repetition time) seconds in the real world, where TR is then the sampling interval. This and other details, make it so that there are principled reasons for doing frequency filtering of the time series. We will assume that \\(M\\) is consisting of processed time series.\nThe basis of functional connectivity is to consider correlations between pairs \\(\\mu_t^n\\), \\(\\mu_t^m\\), for \\(m,n \\in [N]\\), using standard Pearson correlation. That is we consider them as vectors in \\(\\mathbb{R}^T\\).\nFor two vectors \\(x, y \\in \\mathbb{R}^T\\), the Pearson correlation is the cosine distance between mean-centered versions. For two random variables \\(X\\) and \\(Y\\), the correlation is \\[\n\\text{Corr}(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{Var(X)}\\sqrt{Var(Y)}}\n\\]\nand Pearson’s rho is an"
  },
  {
    "objectID": "posts/macroenergy/index.html",
    "href": "posts/macroenergy/index.html",
    "title": "macromacroscale",
    "section": "",
    "text": "it feels like plus and minus are essential, but it is multiplication and division thats the everything, when you consider scale. i love orders of magnitude, just tell me the oom, the sweet ooms, give me the oom and i will add and subtract the exponents.\ni love ooms, i love the idea that you just remember a usually two-digit number and you have some idea of the scale. the scale is what matters. looking at scale protects you from looking too narrow.\nEarth receives O(e17) watts from the sun. We are currently producing O(e12) watts\nif we look at the macroscale what is happening with the planet? we are producing more energy and making more computations and storing more data.\nit is clear by now that while CPUs and GPUs are both part of the new world, the FLOPs in GPUs are going to be extremely dominant. therefore to understand the scale of global compute it might be reasonable to just look at GPU compute. rough estimates from web searches, Claude gives a O(1e22) ops/second.\nwhat about materials. for simplicity we will consider the case of civilising mars. one aspects is minerals. consider looking at mars as this ball, there is some order and disorder at different levels. the different materials are hard to access, you might want to separate some mineral from other minerals etc. it seems some part of what will happen is this refining, this sorting of the minerals.\nthey would try to sort the minerals on the planet, and they would also apply energy to purify the ores etc. in the beginning they might do some crude sorting but once they start purifying using energy where the heat is somehow disposed, they are changing the local entropy, by creating materials with fewer accessible microstates.\nwhy does civilisation do that? civilisation changes the configuration (the point in the configuration space of the solar system.) if there was no intelligence, the area of phase space explored would be very different than what it is with civilisation.\nin no-intelligence, the solar system emits the radiation and it just escapes the solar system. with civilisation the energy is being harnessed to build up chemical potential energy with higher free energy."
  }
]