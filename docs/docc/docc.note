Fremlæggelse til Logos:

Matematikken og logikken giver en måde at formalisere tænkningen.

Man har forsøgt at fastlægge intelligens som en kvantitet ved en menneskelig organisme.
G-faktoren er en psykometrisk stokastisk variabel, der fastlægges på baggrund af
et psykologisk eksperimentelt design, der er konstrueret.

Jeg vil gerne arbejde på en form for eksperimentelt projekt, hvor vi anvender programmer
til at generere mønstre med en hvis kompleksitet.

Til forsvarets dag, hvor unge hverves til det militære institution, er der computertests,
der minder om de preliminære IQ-tests, man kan finde på Mensas website.

Hvad gør IQ-test på computere preliminære? De mangler der er i eksperimentelt design af
en computerbaseret IQ-tests bør adresseres hurtigst muligt, af mindst en grund. Hvis det
først lykkes er vi i stand til at opfange en langt større mængde data, der udgør de
statistiske variable i vores skalare kvantifikation af intelligens. Men udover denne
grund, er der også ønsket om at modellere et mere komplekst faserum, med disse mange variable.
Et sådant projekt er bedst beskrevet under termen computationel psykometri.

Computermodellering giver baggrund for en ontologi, der matematisk funderet ved hjælp
af type systemer. Herved kombineres logikken, statistikken og empirien. Modeller er ikke
blot et værktøj til at forme paragraffer i artikler.

Hvad er et videnskabeligt fakta. Et naturvidenskabeligt fakta er en formel sætning af formen

Den lineære korrelation mellem de stokastiske variable X og Y har værdien c.

Med computationel psykometri kan disse værdier X og Y direkte udledes fra de bits der er genereret
i menneskets interaktion med computeren.

Når mennesket interagerer med et psykometrisk softwaresystem er der en input-output relation;
et tastatur er tilstrækkeligt i de fleste tilfælde. Der er en output relation med skærmen, der
præsenterer information.

Ide: Hvad er Kolmogorov kompleksiteten af den strøm af bytes du kan generere på et tastatur?
Hvis vi har at gøre med en sekventiel processor er der en bestemt antal bytes, der kan modtages,
men hastigheden hvormed en laptop ville kunne gemme alt tastaturinput overgår langt hvad et menneske
nogensinde ville være kunne være begrænset af. Lav hastighed for USB er stadig millioner af bits
i sekundet.

Vi fastsætter et antal sekunder T, hvor vi tillader input. Vi lader mennesket give input i den fastsatte
tid. Vi har derefter en liste af tupler (millisekund, tast-id). Der sker i softwaren en modellering af
disse, som man ikke behøver at gå i dybden med, ved hjælp af computerens modellering af tal.
Den gennemsnitlige hastighed for personen er længden af listen divideret med antal sekunder.

Vi vil nu gerne sige noget om informationsindholdet i listen af tast-id'er, S. Der er en signatur
der går fra typen tast-id streng til decimaltal. Denne signatur er en mængde af funktioner, og idet
vi skriver en bestemt funktion laver vi et eksperimentelt designvalg. Funktionerne såsom Shannon entropi
og varians har værdi, i kraft af deres anvendelsesmuligheder. Problemet med varians, er at vi her vil
tillægge tast-id'erne en kvantitativ betydning, der ikke nødvendigvis er gyldig. Det er ikke en umiddelbart
menigsfuld måde at definere en ulighedsrelation på mængden af taster. Lad X være en stokastisk variabel med
tastID'er som support give antallet af forekomster.

Vi finder nu en modsætning. Shannon entropien vil være højest (log af antallet af taster) hvis variablen
er diskret uniformt fordelt. Men enhver person kunne skabe et input med maksimal entropi ved at gå
i rundte på tastaturet eller ved at smadre løs på tasterne ville man måske kunne lave en approksimation.
Alt dette betyder at der ingen direkte sammenhæng mellem entropi og vores begreb om kommunikeret indhold,
konceptuelt set. Det er fordi vi i et signal, forventer noget, der er en mental besked, der dannes i
hjernen og giver baggrund for et mere velovervejet input. Intelligens udgår fra en struktur, hvor hver
eneste tegn ikke er uafhængig af de andre.

Chomsky hierarkiet beskriver en niveau af strukturer af stigende computationel kapacitet, der har
direkte sammenhæng med automater. En klasse af automater repræsenterer en klasse af sprog. Fra automatens
vinkel kan vi tænke det som en funktion, der fortæller os om en streng er medlem af et givent sprog
eller ikke. Chomsky tænker det dog generativt, hans formelle grammatikker skal tænkes som et objekt,
der genererer alle strenge i sproget rekursivt.

Hvordan hænger disse automater og sprog sammen med vores signal? En bestemt streng kan genereres af
en begrænset automat A, der accepterer blot denne streng, eller en anden B der accepterer alle.
Hvis det er A, så er den uniforme fordeling på X ikke et udtryk for tilfældig sampling af alle
mulige strenge, det vil altid kun være denne ene streng der genereres.

Vi vil nu gerne forbinde to koncepter; automater og stokastiske kilder. Spørgsmålet om stationaritet
er central for denne kobling. 

En markov kæde er en sekvens af stokastiske variable hvor fordelingen er lig fordelingen betinget
på udfaldet af den foregående variabel. Mere generelt tænker vi os et netværk at nodes, der repræsenterer
udfaldsrummet hvor hver node har en fordeling, der beskriver sandsynligheden for at bevæge sig til
en anden state. Vi kan sige at et givent netværk med en given start position genererer et sprog med længde
t. Hvor sproget er mængden af strenge der ville kunne forekomme ved at lave hop fra startnoden rundt
i udfaldsrummet. Modsat, hvis det for en given markov kæde gælder, at sandsynligheden for hop fra tegn A til
tegn B er 0, er strenge med delstregen AB ikke en del af det genererede sprog.

For t generative hop findes der en multivariat fordeling af sandsynligheden for en streng af længde t,
der findes ved at multiplicere sandsynlighederne. T hop definerer en stokastisk vektor af længde n.
Hvis man lavede en t-dimensionel tabel for sandsynligheden for en given vektor, ville bare små t give
enorme tabeller. Vi vender os nu igen fra det generative tilbage til det verificerende, idet Markov kæden
selv er en god komprimering af denne tabel. Det er dog ikke givet at markovkæden er optimal. Vi kan
sagtens have redundans i markovkæden, ligesom vi kan det i begrænsede automater.

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.3344&rep=rep1&type=pdf

Den rene analyse af råt input er blot en vej i kvantificering af intelligens. Vi kan også forsøge at
lave abstraktioner af tanken bag nuværende intelligenstest, der baserer sig på mønstergenkendelse, hvor
man på baggrund af eksempler i enten en mængde eller en sekvens bliver bedt om at forudsige det manglende
element. En opgave der beder en person forudsige det næste element i en række af tal eller mere abstrakte
objekter er interesssant at analysere: Matematisk set findes alle rækker af tal, og derfor

Psykedelika

Meditation, mindfulness

Der er ikke en bijektion mellem sprog og automater, fordi flere automater kan beskrive det samme sprog.
Dette er direkte relateret til forskningen i minimering af boolske netværk. Det er muligt at etablere
forskellige metrikker for minimering af automater, først angående states V. I deterministiske begrænsede
automater er antallet af transitioner/kanter E altid n gange størrelsen på alfabetet.

I algoritmisk implementering af Markovkæder vil man have en grafstruktur eller en stokastisk matrix.
Matrixrepræsentationer bruger O(V^2) plads, listerepræsentationer O(V + E) plads. I mange systemer der
ønskes modelleret vil vi finde at deres strukturer er tynde, altså at der er mange transitioner der har
sandsynlighed 0 eller blot lav sandsynlighed. Her vil en listerepræsentation have et fordelagtigt
pladsforbrug. Vi vil altså kvantiteten V + E generelt, eventuelt med V og E vægtet i forhold til
konkret pladsforbrug.

Man vil gerne lave en funktion, der går fra graf til sandsynlighed for at generere denne streng.
Det følger direkte af tidligere diskussioner, at en Moore-Markov automat ville kunne generere lige
præcis denne streng med sandsynlighed 1. I en Moore-Markov automat ville der være en start automat,
hvor noget sådant gjaldt. Vi starter altså altid fra samme punkt, der er dog problemer i dette,
fordi vi dermed ikke betragter strengen som et delsignal af en form for stationærprocess, hvor vi
ligesåvel kunne have taget en anden.

Det kan bliver meget abstrakt, hvis vi nu begynder at forestille os en stokastisk process, hvor tiden
er både negative og positive heltal.

Samfundsudvikling

Psykologi