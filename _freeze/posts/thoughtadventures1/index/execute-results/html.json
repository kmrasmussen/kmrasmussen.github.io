{
  "hash": "3ecb1c614fde867a0a5b8155484a8069",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"thought adventures 1\"\ndate: \"2025-06-04\"\n---\n\nyesterday, i did a curious adventures that was a lot about learning things by talking to 4o. today, i don't have much time to go on adventure, but i will focus more on speculation than on learning.\n\nwhat is some thing i have been thinking about recently?\n\nwhen doing breath meditation, mindwandering is an important notion. we can perhaps imagine that the mind follows a trajectory in some kind of space, $x(t) \\in \\mathcal{X}$. We can also imagine that maybe this trajectory is stochastic in some sense, but maybe will wait.\n\nI will use it as a word \"introspectively\" for \"what i conclude when i try to think about what i experience in meditation\".\n\nIntrospectively, time is very fine-grained an consists of a single percept. So in that case we have to think of $\\mathcal{X}$ as a set of percpets. These percepts are complex objects, and one important aspect is that they differ by many \"ooms\" in how much they cause some kind of reaction. This means that some percept, it can be an internal image of a person, can have a certain kind of salience. Introspectively, percepts with a high value are \"on average\" followed by more of percepts that are \"related\".\n\nSimplistically we might imagine some kind of entity that controls inputs from multiple different sources. These sources may be more \"sensory\" or they might be more \"internal\", such as images generated by fantasies or planning etc.\n\nI then imagine $x(t)$ as a kind of controlled sampling from these sources, where each source has its own trajectories and you get a sample from one of them.\n\nThis controlled sampler is a mechanism of attention. I then imagine that we can view the space from two perspectives, we can view it as discrete moments where we get a sample from each, or we can look at the relative abundance of samples from each source, almost as if we are looking across small intervals $\\Delta t$.\n\nI don't know whether to think of these sources as specific brain areas or more distributed, for now we are restricting to a kind of combination of introspection and formalizing, where we try to throw around ideas for formalizations of what we introspect. Introspection is different from awareness of the things, it invovles a kind of balance between rationalization and awareness.\n\nHave you ever seen these videos showing a world map and the change of borders as different countries conquer each other an so on? There is some kind of finite resource, the area of land in the world and then there are these entities, countries, that vary in their territory. New ones can arise at some point and also end at some point.\n\nMaybe the idea of a chinese restaurant process is relevant. In chinese room with some probability you make a new restaurant table for the new customer if not you assign to an existing table based on normalized table size count. $P(new) = \\frac{\\alpha}{t-1+\\alpha}$. The sizes of tables will follow a power-law.\n\n::: {#8488efb5 .cell execution_count=1}\n``` {.python .cell-code}\n'''\nimport numpy as np\nT = 100000\ntable_sizes = []\nalpha = 50\n\nfor t in range(1,T):\n  p_new = 0.2 if t > 0 else 1 \n  #print('pnew', p_new)#alpha/(t-1+alpha)\n  do_new = np.random.binomial(n=1,p=p_new)\n  if do_new == 1:\n    table_sizes.append(1)\n  else:\n    existing_normalized = np.array(table_sizes).astype(np.float32)\n    existing_normalized /= existing_normalized.sum()\n    assigned_table = np.random.choice(len(table_sizes),p=existing_normalized)\n    table_sizes[assigned_table] += 1\nimport matplotlib.pyplot as plt\ntable_sizes_np = np.array(table_sizes)\nprint('number of tables', table_sizes_np.shape)\ntable_sizes_np.sort()\ntable_sizes_np = table_sizes_np[::-1]\nranks = np.arange(1, len(table_sizes_np)+1)\nplt.loglog(ranks, table_sizes_np, marker='.')\n'''\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n\"\\nimport numpy as np\\nT = 100000\\ntable_sizes = []\\nalpha = 50\\n\\nfor t in range(1,T):\\n  p_new = 0.2 if t > 0 else 1 \\n  #print('pnew', p_new)#alpha/(t-1+alpha)\\n  do_new = np.random.binomial(n=1,p=p_new)\\n  if do_new == 1:\\n    table_sizes.append(1)\\n  else:\\n    existing_normalized = np.array(table_sizes).astype(np.float32)\\n    existing_normalized /= existing_normalized.sum()\\n    assigned_table = np.random.choice(len(table_sizes),p=existing_normalized)\\n    table_sizes[assigned_table] += 1\\nimport matplotlib.pyplot as plt\\ntable_sizes_np = np.array(table_sizes)\\nprint('number of tables', table_sizes_np.shape)\\ntable_sizes_np.sort()\\ntable_sizes_np = table_sizes_np[::-1]\\nranks = np.arange(1, len(table_sizes_np)+1)\\nplt.loglog(ranks, table_sizes_np, marker='.')\\n\"\n```\n:::\n:::\n\n\nokay whatever\n\n# landscapes\nso we imagine that somehow there is a landscape, where there are certain attractors. there is stochasticity, so we are not converging to a single percept but locally in time most of the percepts will be about a specific \"topic\"\n\nthe temperature controls the flatness.\n\nin breath meditation we are controlling the system to be in a state that is not an attractor. however, frequent breath meditation, in my experience, makes the sensory stimuli from the nose region almost like an attractor.\n\nwhen meditating for 30 minutes, as opposed to having normal resting state where mind wanders freely, you get two different distributions of time spent in the attractors.\n\nhowever, i think this misses the important part, the important part may be the relationship between temporally close percepts.\n\nfor an interval of 10 seconds $\\Delta t$, consider the fraction of percepts at the meditation object, call it $\\phi_{\\Delta t}(t)$. Breath meditation generally seeks relatively high such values. Depending on your goal for meditation, many people aim for too high values of $\\phi$.\n\nWe can consider a mindwandering episode to be a stretch of time where $\\phi(t)$ falls from its desired value $\\phi^*$ along with the the increase of the fraction of percepts $\\psi_A(t)$ associated with some attractor $A$.\n\nI contend that high values of $\\phi$ is generally, is associated with some kind of temporal mixing of attractor percepts. And this mixing is even higher for noting meditation. Though not necessarily changing the relative power/size/abundance of the attractors, you are sampling them in a more mixed way, essentially reducing the autocorrelation. Introspectively, especially in noting meditation, this is experienced as a kind of temporal shattering of thought processes, where no thought process can survive sufficiently long. There can also be a related kind of spatial shattering, but that would be a bit unrelated to what I am discussing now.\n\nI guess a way to talk about this is that we can think that the marginal probability of a state might stay the same, and shattering is associated with moving the condition distribution on percepts closer to the marginal.\n\nthe speculation is then that this has some desirable effects, to have mixing. i want to imagine that there is some global capacity, and that mostly the attractors are using up all the capacity. they are maintaining their reach, their territory, through a reinforcement that is related to the temporal associations, and mixing is reducing this.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}